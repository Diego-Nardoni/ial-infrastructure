#!/usr/bin/env python3
"""
IAL Conversational Engine - Interface conversacional igual Amazon Q
Implementa capacidades de Query + Provisioning com contexto de conversa
"""

import json
from typing import Dict, List, Optional
from datetime import datetime

class ConversationContext:
    """Gerencia contexto e memÃ³ria da conversa"""
    
    def __init__(self):
        self.history = []
        self.current_session = {
            'start_time': datetime.now(),
            'user_inputs': [],
            'responses': [],
            'context_data': {}
        }
        # Inicializar Context Engine (jÃ¡ tem MemoryManager + Embeddings)
        try:
            from .memory.context_engine import ContextEngine
            self.context_engine = ContextEngine()
            self.memory_manager = self.context_engine.memory
        except Exception as e:
            self.context_engine = None
            self.memory_manager = None
    
    def add_user_input(self, user_input: str):
        """Adiciona input do usuÃ¡rio ao contexto"""
        self.current_session['user_inputs'].append({
            'timestamp': datetime.now(),
            'input': user_input
        })
    
    def add_response(self, response: str):
        """Adiciona resposta ao contexto"""
        self.current_session['responses'].append({
            'timestamp': datetime.now(),
            'response': response
        })
    
    def get_recent_context(self, limit: int = 3) -> List[Dict]:
        """Retorna contexto recente da conversa"""
        return self.current_session['user_inputs'][-limit:]

class QueryEngine:
    """Engine para consultas AWS via MCP servers - Wrapper para IALQueryEngine"""
    
    def __init__(self):
        # Usar o engine real implementado
        try:
            from .ial_query_engine import QueryEngineIntegration
            self.real_engine = QueryEngineIntegration()
            self.use_real_engine = True
        except ImportError:
            print("âš ï¸ IALQueryEngine nÃ£o encontrado, usando simulaÃ§Ã£o")
            self.use_real_engine = False
            self.mcp_clients = {
                'aws_resources': 'mcp-aws-resources',
                'cost_explorer': 'mcp-cost-explorer', 
                'cloudwatch': 'mcp-cloudwatch',
                'cloudtrail': 'mcp-cloudtrail'
            }
    
    def process_via_mcp(self, query: str) -> Dict:
        """Processar queries via MCP servers"""
        
        if self.use_real_engine:
            # Usar engine real com MCP servers
            return self.real_engine.process_query_sync(query)
        else:
            # Fallback para simulaÃ§Ã£o
            return self._process_simulated_query(query)
    
    def _process_simulated_query(self, query: str) -> Dict:
        """Processar query simulada (fallback)"""
        query_lower = query.lower()
        
        if 'bucket' in query_lower or 's3' in query_lower:
            return self._query_s3_buckets()
        elif 'ec2' in query_lower or 'instanc' in query_lower:
            return self._query_ec2_instances()
        elif 'cloudtrail' in query_lower or 'log' in query_lower:
            return self._query_cloudtrail_logs(query)
        elif 'custo' in query_lower or 'cost' in query_lower:
            return self._query_current_costs()
        elif 'cloudwatch' in query_lower or 'metric' in query_lower:
            return self._query_cloudwatch_metrics(query)
        else:
            return self._query_general_resources(query)
    
    def _query_s3_buckets(self) -> Dict:
        """Liste buckets S3 via MCP"""
        # SimulaÃ§Ã£o - seria chamada MCP real
        return {
            'type': 's3_buckets',
            'total': 6,
            'buckets': [
                {'name': 'ial-terraform-state', 'region': 'us-east-1', 'size': '2.1GB', 'cost': '$0.05'},
                {'name': 'ial-artifacts-prod', 'region': 'us-east-1', 'size': '15.3GB', 'cost': '$0.35'},
                {'name': 'ial-logs-backup', 'region': 'us-east-1', 'size': '45.2GB', 'cost': '$1.04'},
                {'name': 'ial-data-lake', 'region': 'us-east-1', 'size': '128.7GB', 'cost': '$2.96'},
                {'name': 'ial-static-assets', 'region': 'us-east-1', 'size': '8.9GB', 'cost': '$0.20'},
                {'name': 'ial-backup-cross-region', 'region': 'us-west-2', 'size': '67.4GB', 'cost': '$1.55'}
            ],
            'total_cost': '$6.15'
        }
    
    def _query_ec2_instances(self) -> Dict:
        """Liste instÃ¢ncias EC2 via MCP"""
        return {
            'type': 'ec2_instances',
            'total': 8,
            'prod_count': 4,
            'staging_count': 4,
            'production': [
                {'id': 'i-0123456789abcdef0', 'type': 't3.large', 'state': 'running', 'cost': '$61.32'},
                {'id': 'i-0987654321fedcba0', 'type': 't3.medium', 'state': 'running', 'cost': '$30.66'},
                {'id': 'i-0abcdef123456789', 'type': 't3.large', 'state': 'running', 'cost': '$61.32'},
                {'id': 'i-0fedcba987654321', 'type': 't3.small', 'state': 'running', 'cost': '$15.33'}
            ],
            'staging': [
                {'id': 'i-0111222333444555', 'type': 't3.micro', 'state': 'running', 'cost': '$7.67'},
                {'id': 'i-0555444333222111', 'type': 't3.micro', 'state': 'stopped', 'cost': '$0.00'},
                {'id': 'i-0666777888999000', 'type': 't3.small', 'state': 'running', 'cost': '$15.33'},
                {'id': 'i-0000999888777666', 'type': 't3.micro', 'state': 'running', 'cost': '$7.67'}
            ],
            'total_cost': '$199.30',
            'alerts': ['dev-sandbox idle hÃ¡ 3 dias', 'staging-02 stopped mas com EBS attached']
        }
    
    def _query_cloudtrail_logs(self, query: str) -> Dict:
        """Logs CloudTrail via MCP"""
        if 'login' in query.lower():
            return {
                'type': 'cloudtrail_security',
                'event_type': 'failed_logins',
                'threats_detected': 23,
                'suspicious_ips': ['1.2.3.4', '5.6.7.8'],
                'affected_users': ['admin@company.com', 'root'],
                'time_window': '24 hours',
                'security_score': 65,
                'immediate_actions': [
                    'Bloquear IP 1.2.3.4 no Security Group',
                    'Resetar senha do usuÃ¡rio admin@company',
                    'Habilitar MFA se nÃ£o estiver ativo'
                ]
            }
        return {'type': 'cloudtrail_general', 'events': []}
    
    def _query_current_costs(self) -> Dict:
        """Custos atuais via MCP Cost Explorer"""
        return {
            'type': 'cost_analysis',
            'current_month': '$245.67',
            'last_month': '$198.43',
            'trend': 'increasing',
            'top_services': [
                {'service': 'EC2', 'cost': '$199.30', 'percentage': 81.1},
                {'service': 'S3', 'cost': '$6.15', 'percentage': 2.5},
                {'service': 'CloudWatch', 'cost': '$12.45', 'percentage': 5.1},
                {'service': 'VPC', 'cost': '$8.90', 'percentage': 3.6},
                {'service': 'Others', 'cost': '$18.87', 'percentage': 7.7}
            ],
            'optimization_opportunities': [
                {'type': 'rightsizing', 'potential_savings': '$45.20', 'description': 'Reserved Instances para prod'},
                {'type': 'storage', 'potential_savings': '$12.50', 'description': 'S3 objects elegÃ­veis para IA'},
                {'type': 'idle_resources', 'potential_savings': '$15.18', 'description': 'dev-sandbox idle hÃ¡ 3 dias'}
            ]
        }
    
    def _query_cloudwatch_metrics(self, query: str) -> Dict:
        """MÃ©tricas CloudWatch via MCP"""
        return {
            'type': 'cloudwatch_metrics',
            'metric_type': 'cpu_utilization',
            'instances': [
                {'id': 'i-0123456789abcdef0', 'avg_cpu': 85.2, 'status': 'high'},
                {'id': 'i-0987654321fedcba0', 'avg_cpu': 45.1, 'status': 'normal'},
                {'id': 'i-0abcdef123456789', 'avg_cpu': 12.3, 'status': 'low'}
            ],
            'recommendations': ['Scale up prod-web-01 para t3.large', 'Adicionar auto-scaling group']
        }
    
    def _query_general_resources(self, query: str) -> Dict:
        """Query geral de recursos"""
        return {
            'type': 'general_query',
            'message': f'Processando query: {query}',
            'suggestions': ['Seja mais especÃ­fico sobre o recurso', 'Tente: "liste buckets" ou "quantas EC2"']
        }

class IALConversationalEngine:
    """Engine conversacional principal - Interface igual Amazon Q"""
    
    def __init__(self):
        self.query_engine = QueryEngine()
        self.conversation_context = ConversationContext()
        
        # Inicializar context_engine
        self.context_engine = None
        try:
            from .memory.context_engine import ContextEngine
            self.context_engine = ContextEngine()
        except ImportError:
            pass
        
        # Importar engines existentes (fallback)
        try:
            from .ial_orchestrator_stepfunctions import IALOrchestratorStepFunctions
            from .ial_orchestrator_mcp_first import IALOrchestratorMCPFirst
            from .ial_orchestrator import IALOrchestrator
            
            self.stepfunctions_orchestrator = IALOrchestratorStepFunctions()
            self.mcp_first_orchestrator = IALOrchestratorMCPFirst()
            self.python_orchestrator = IALOrchestrator()
        except ImportError:
            self.stepfunctions_orchestrator = None
            self.mcp_first_orchestrator = None
            self.python_orchestrator = None
    
    def process_conversational_input(self, user_input: str) -> str:
        """Interface conversacional principal"""
        
        # 1. Construir contexto semÃ¢ntico relevante (SEMPRE)
        context = ""
        if self.context_engine:
            try:
                context = self.context_engine.build_context_for_query(user_input)
            except Exception as e:
                pass  # Silenciar
        
        # 2. Manter contexto da conversa local
        self.conversation_context.add_user_input(user_input)
        
        # 3. Preparar input enriquecido com contexto (LLM decide se usa)
        enriched_input = user_input
        if context:
            enriched_input = f"""HistÃ³rico de conversas anteriores:
{context}

---
Pergunta atual do usuÃ¡rio: {user_input}"""
        
        # 4. Detectar tipo de intenÃ§Ã£o
        intent_type = self._classify_intent(user_input)
        
        # 5. Processar baseado no tipo
        if intent_type == "query":
            result = self.query_engine.process_via_mcp(enriched_input)
            response = self._format_query_response(result)
            
        elif intent_type == "provisioning":
            if self._has_provisioning_engines():
                result = self._execute_provisioning_chain(enriched_input)
                response = self._format_provisioning_response(result)
            else:
                response = "ðŸš§ Provisioning engines nÃ£o disponÃ­veis. Modo query-only ativo."
                
        elif intent_type == "troubleshooting":
            result = self.query_engine.process_via_mcp(enriched_input)
            response = self._format_troubleshooting_response(result)
        
        else:
            response = self._format_help_response()
        
        # 6. Adicionar sugestÃµes contextuais
        response += self._generate_contextual_suggestions(user_input, intent_type)
        
        # 7. Salvar interaÃ§Ã£o completa (user + assistant) com embeddings
        if self.context_engine:
            try:
                self.context_engine.save_interaction(user_input, response)
            except Exception:
                pass  # Silenciar
        
        # 8. Salvar no contexto local
        self.conversation_context.add_response(response)
        
        return response
    
    def _classify_intent(self, user_input: str) -> str:
        """Detectar tipo de intenÃ§Ã£o"""
        
        query_keywords = ['liste', 'quantos', 'quantas', 'verificar', 'logs', 'status', 'custo', 'cost', 'show', 'describe']
        provisioning_keywords = ['criar', 'quero', 'preciso', 'deploy', 'provisionar', 'create']
        troubleshooting_keywords = ['problema', 'erro', 'lento', 'falha', 'nÃ£o funciona', 'debug']
        
        user_lower = user_input.lower()
        
        if any(keyword in user_lower for keyword in query_keywords):
            return "query"
        elif any(keyword in user_lower for keyword in provisioning_keywords):
            return "provisioning"
        elif any(keyword in user_lower for keyword in troubleshooting_keywords):
            return "troubleshooting"
        else:
            return "unknown"
    
    def _has_provisioning_engines(self) -> bool:
        """Verifica se engines de provisioning estÃ£o disponÃ­veis"""
        return (self.stepfunctions_orchestrator is not None or 
                self.mcp_first_orchestrator is not None or 
                self.python_orchestrator is not None)
    
    def _execute_provisioning_chain(self, user_input: str) -> Dict:
        """Cadeia de fallback para provisioning"""
        
        try:
            # 1. TENTAR Step Functions primeiro
            if self.stepfunctions_orchestrator:
                return self.stepfunctions_orchestrator.process_nl_intent(user_input)
        except Exception as e:
            print(f"âš ï¸ Step Functions falhou: {e}")
            
            try:
                # 2. TENTAR MCP-first
                if self.mcp_first_orchestrator:
                    return self.mcp_first_orchestrator.process_nl_intent(user_input)
            except Exception as e:
                print(f"âš ï¸ MCP-first falhou: {e}")
                
                # 3. FALLBACK Python
                if self.python_orchestrator:
                    return self.python_orchestrator.process_nl_intent(user_input)
        
        return {"error": "Todos os orquestradores falharam", "status": "error"}
    
    def _format_query_response(self, result: Dict) -> str:
        """Formatar resposta de query igual Amazon Q"""
        
        # Usar formatter avanÃ§ado se disponÃ­vel
        try:
            from .response_formatter import ResponseFormatterIntegration
            formatter = ResponseFormatterIntegration()
            return formatter.format_response(result)
        except ImportError:
            # Fallback para formataÃ§Ã£o simples
            return self._format_simple_response(result)
    
    def _format_simple_response(self, result: Dict) -> str:
        """FormataÃ§Ã£o simples (fallback)"""
        if result['type'] == 's3_buckets':
            return self._format_s3_response(result)
        elif result['type'] == 'ec2_instances':
            return self._format_ec2_response(result)
        elif result['type'] == 'cloudtrail_security':
            return self._format_security_response(result)
        elif result['type'] == 'cost_analysis':
            return self._format_cost_response(result)
        elif result['type'] == 'cloudwatch_metrics':
            return self._format_metrics_response(result)
        else:
            return f"ðŸ“Š **Resultado:** {result.get('message', 'Query processada')}"
    
    def _format_s3_response(self, result: Dict) -> str:
        """Formatar resposta S3 igual Amazon Q"""
        
        bucket_rows = ""
        for bucket in result['buckets']:
            bucket_rows += f"â”‚ {bucket['name']:<19} â”‚ {bucket['region']:<8} â”‚ {bucket['size']:<7} â”‚ {bucket['cost']:<12} â”‚\n"
        
        return f"""ðŸ“¦ **Buckets S3 encontrados ({result['total']} total):**

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Nome                â”‚ RegiÃ£o   â”‚ Tamanho â”‚ Custo/mÃªs    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
{bucket_rows}â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸ’° **Custo total:** {result['total_cost']}/mÃªs"""
    
    def _format_ec2_response(self, result: Dict) -> str:
        """Formatar resposta EC2 igual Amazon Q"""
        
        prod_list = "\n".join([f"â€¢ {inst['id']} ({inst['type']}) - {inst['cost']}/mÃªs" for inst in result['production']])
        staging_list = "\n".join([f"â€¢ {inst['id']} ({inst['type']}) - {inst['cost']}/mÃªs" for inst in result['staging']])
        alerts_list = "\n".join([f"â€¢ {alert}" for alert in result['alerts']])
        
        return f"""ðŸ–¥ï¸ **InstÃ¢ncias EC2 ativas ({result['total']} total):**

**ðŸŸ¢ ProduÃ§Ã£o ({result['prod_count']} instÃ¢ncias):**
{prod_list}

**ðŸŸ¡ Staging ({result['staging_count']} instÃ¢ncias):**
{staging_list}

ðŸ’° **Custo total:** ${result['total_cost']}/mÃªs

âš ï¸ **Alertas:**
{alerts_list}"""
    
    def _format_security_response(self, result: Dict) -> str:
        """Formatar anÃ¡lise de seguranÃ§a igual Amazon Q"""
        
        actions_list = "\n".join([f"â€¢ {action}" for action in result['immediate_actions']])
        
        return f"""ðŸš¨ **AnÃ¡lise de SeguranÃ§a CloudTrail:**

ðŸ›¡ï¸ **Security Score:** {result['security_score']}/100

**âŒ AmeaÃ§as detectadas ({result['threats_detected']} eventos):**
â€¢ IPs suspeitos: {', '.join(result['suspicious_ips'])}
â€¢ UsuÃ¡rios afetados: {', '.join(result['affected_users'])}
â€¢ Janela de tempo: {result['time_window']}

ðŸ” **AnÃ¡lise de padrÃµes:**
â€¢ IP 1.2.3.4: 15 tentativas em 2 minutos (possÃ­vel brute force)
â€¢ UsuÃ¡rio admin@company: 23 falhas consecutivas
â€¢ Origem: NÃ£o reconhecida (fora da rede corporativa)

ðŸ›¡ï¸ **AÃ§Ãµes imediatas recomendadas:**
{actions_list}"""
    
    def _format_cost_response(self, result: Dict) -> str:
        """Formatar anÃ¡lise de custos igual Amazon Q"""
        
        services_list = "\n".join([f"â€¢ {svc['service']}: ${svc['cost']} ({svc['percentage']}%)" for svc in result['top_services']])
        savings_list = "\n".join([f"â€¢ {opt['description']} â†’ Economia: ${opt['potential_savings']}/mÃªs" for opt in result['optimization_opportunities']])
        
        return f"""ðŸ’° **AnÃ¡lise de Custos AWS:**

ðŸ“Š **Resumo atual:**
â€¢ Este mÃªs: ${result['current_month']}
â€¢ MÃªs anterior: ${result['last_month']}
â€¢ TendÃªncia: {result['trend']} ðŸ“ˆ

**ðŸ’¸ Top serviÃ§os por custo:**
{services_list}

**ðŸŽ¯ Oportunidades de otimizaÃ§Ã£o:**
{savings_list}

**ðŸ’¡ Economia total potencial: ${sum(float(opt['potential_savings'].replace('$', '')) for opt in result['optimization_opportunities']):.2f}/mÃªs**"""
    
    def _format_metrics_response(self, result: Dict) -> str:
        """Formatar mÃ©tricas CloudWatch"""
        
        instances_list = "\n".join([f"â€¢ {inst['id']}: {inst['avg_cpu']}% CPU ({inst['status']})" for inst in result['instances']])
        recommendations_list = "\n".join([f"â€¢ {rec}" for rec in result['recommendations']])
        
        return f"""ðŸ“Š **MÃ©tricas CloudWatch - CPU Utilization:**

**ðŸ–¥ï¸ InstÃ¢ncias analisadas:**
{instances_list}

**ðŸ’¡ RecomendaÃ§Ãµes:**
{recommendations_list}"""
    
    def _format_provisioning_response(self, result: Dict) -> str:
        """Formatar resposta de provisioning igual Amazon Q"""
        
        if result.get('status') == 'error':
            return f"âŒ **Erro no provisioning:** {result.get('error', 'Erro desconhecido')}"
        
        return f"""ðŸ§  **Interpretando sua intenÃ§Ã£o:**
â€¢ ServiÃ§o: {result.get('detected_services', 'N/A')}
â€¢ ConfiguraÃ§Ã£o: {result.get('configuration', 'N/A')}
â€¢ RegiÃ£o: {result.get('region', 'us-east-1')}

âœ… **Provisioning iniciado com sucesso!**

ðŸ“¬ **PrÃ³ximos passos:**
â€¢ Gerando YAML files...
â€¢ Criando Pull Request no GitHub...
â€¢ Pipeline CI/CD serÃ¡ executado automaticamente"""
    
    def _format_troubleshooting_response(self, result: Dict) -> str:
        """Formatar resposta de troubleshooting"""
        
        if result['type'] == 'cloudwatch_metrics':
            return f"""ðŸ” **AnÃ¡lise de Performance:**

{self._format_metrics_response(result)}

ðŸ› ï¸ **DiagnÃ³stico:**
â€¢ Problema identificado: CPU alta em algumas instÃ¢ncias
â€¢ Impacto: Performance degradada da aplicaÃ§Ã£o
â€¢ SoluÃ§Ã£o recomendada: Scale up ou auto-scaling"""
        
        return "ðŸ” **Troubleshooting em andamento...** Analisando logs e mÃ©tricas."
    
    def _format_help_response(self) -> str:
        """Resposta de ajuda"""
        
        return """ðŸ¤– **IAL Assistant - Como posso ajudar?**

**ðŸ“Š Consultas (Query):**
â€¢ "liste todos os buckets"
â€¢ "quantas EC2 eu tenho"
â€¢ "verifique logs cloudtrail"
â€¢ "qual o custo atual"

**ðŸš€ Provisioning:**
â€¢ "quero ECS com Redis"
â€¢ "criar VPC privada"
â€¢ "deploy aplicaÃ§Ã£o serverless"

**ðŸ” Troubleshooting:**
â€¢ "por que estÃ¡ lento?"
â€¢ "problema de login"
â€¢ "debug performance"

Digite sua pergunta ou comando!"""
    
    def _generate_contextual_suggestions(self, user_input: str, intent_type: str) -> str:
        """Gerar sugestÃµes contextuais baseadas na conversa"""
        
        # Usar formatter avanÃ§ado se disponÃ­vel
        try:
            from .response_formatter import ResponseFormatterIntegration
            formatter = ResponseFormatterIntegration()
            return formatter.format_contextual_suggestions(user_input, intent_type)
        except ImportError:
            # Fallback para sugestÃµes simples
            return self._generate_simple_suggestions(user_input, intent_type)
    
    def _generate_simple_suggestions(self, user_input: str, intent_type: str) -> str:
        """Gerar sugestÃµes simples (fallback)"""
        suggestions = []
        
        if intent_type == "query":
            if 'bucket' in user_input.lower():
                suggestions.extend([
                    "â€¢ Quer configurar lifecycle policies para otimizar custos?",
                    "â€¢ Precisa analisar padrÃµes de acesso aos objetos?",
                    "â€¢ Quer configurar replicaÃ§Ã£o cross-region?"
                ])
            elif 'ec2' in user_input.lower():
                suggestions.extend([
                    "â€¢ Quer analisar utilizaÃ§Ã£o de CPU/memÃ³ria?",
                    "â€¢ Precisa configurar auto-scaling?",
                    "â€¢ Quer otimizar custos com Reserved Instances?"
                ])
            elif 'custo' in user_input.lower():
                suggestions.extend([
                    "â€¢ Quer implementar as otimizaÃ§Ãµes sugeridas?",
                    "â€¢ Precisa configurar alertas de budget?",
                    "â€¢ Quer anÃ¡lise detalhada por projeto?"
                ])
        
        elif intent_type == "provisioning":
            suggestions.extend([
                "â€¢ Quer acompanhar o progresso do deploy?",
                "â€¢ Precisa ajustar alguma configuraÃ§Ã£o?",
                "â€¢ Quer configurar monitoramento para os recursos?"
            ])
        
        if suggestions:
            return f"\n\nðŸ’¡ **SugestÃµes:**\n" + "\n".join(suggestions)
        
        return ""

# Interface CLI para testes
if __name__ == "__main__":
    engine = IALConversationalEngine()
    
    print("ðŸ¤– IAL Conversational Engine - Modo Teste")
    print("Digite 'quit' para sair\n")
    
    while True:
        user_input = input("IAL> ").strip()
        
        if user_input.lower() in ['quit', 'exit', 'sair']:
            print("ðŸ‘‹ AtÃ© logo!")
            break
        
        if user_input:
            response = engine.process_conversational_input(user_input)
            print(f"\n{response}\n")

    def _format_history_response(self, history: List[Dict], user_input: str) -> str:
        """Formatar resposta com histÃ³rico de conversas"""
        response = "ðŸ“œ **HistÃ³rico de Conversas Recentes:**\n\n"
        
        for msg in history[-10:]:  # Ãšltimas 10 mensagens
            role = msg.get('role', 'unknown')
            content = msg.get('content', '')
            timestamp = msg.get('timestamp', '')
            
            emoji = "ðŸ‘¤" if role == "user" else "ðŸ¤–"
            response += f"{emoji} **{role.title()}** ({timestamp}):\n{content[:200]}...\n\n"
        
        return response
